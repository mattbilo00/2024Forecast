{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scrape county results for each presidential election from wiki and put into csv format\n",
    "* Need to add 1988_Louisiana manually since it wasn't parsed correctly\n",
    "* Alaska results are not displayed on wiki - will only use statewide results as training data for AK\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the variables\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "years = [1976, 1980, 1984, 1988, 1992, 1996]\n",
    "fips_file = '/Users/mattg/Personal Projects/2024_forecast/Data/fips_info.csv'\n",
    "\n",
    "df = pd.read_csv(fips_file)\n",
    "states = df['StateName'].unique()\n",
    "\n",
    "# To replace spaces with underscores for links\n",
    "states = [state.replace(' ', '_') for state in states]\n",
    "states = [state.replace('District_of_Columbia', 'the_District_of_Columbia') for state in states]\n",
    "states = [state.replace('Washington', 'Washington_(state)') for state in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733b6d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## OPTIONAL: Check that each url exists\n",
    "for yr in years:  \n",
    "    for state in states:    \n",
    "        res_url = f'https://en.wikipedia.org/wiki/{yr}_United_States_presidential_election_in_{state}'\n",
    "        response = requests.get(res_url)\n",
    "        print(f\"{yr}: {state}\")\n",
    "        # Check if the URL returns a 200 response code, indicating the page is accessible\n",
    "        if response.status_code != 200:        \n",
    "            print(f\"{yr}: {state}\")\n",
    "            \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf430ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## OPTIONAL: Displays which states and years have a county table\n",
    "for yr in years:  \n",
    "    for state in states:    \n",
    "        res_url = f'https://en.wikipedia.org/wiki/{yr}_United_States_presidential_election_in_{state}'\n",
    "        response = requests.get(res_url)\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "        \n",
    "        if table:\n",
    "            # Find the header row\n",
    "            header_row = table.find('tr')\n",
    "            if header_row:\n",
    "                # Extract headers\n",
    "                headers = [th.get_text(strip=True) for th in header_row.find_all('th')]\n",
    "                # Check if any header contains the word \"County\"\n",
    "                contains_county = any((\"County\" or \"Parish\") in header for header in headers)\n",
    "                print(f\"{yr}, {state.replace('_', ' ')}, {contains_county}\")\n",
    "            else:\n",
    "                print(f\"{yr}, {state.replace('_', ' ')}, NO COUNTY\")\n",
    "                print(res_url)\n",
    "        else:\n",
    "            print(f\"{yr}, {state.replace('_', ' ')}, NO TABLE\")\n",
    "            print(res_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce864b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Places every table into a df, and each df into a dictionary\n",
    "results = {}\n",
    "for yr in years:\n",
    "    for state in states:\n",
    "        print(f\"{yr}: {state}\")\n",
    "        res_url = f'https://en.wikipedia.org/wiki/{yr}_United_States_presidential_election_in_{state}'\n",
    "        response = requests.get(res_url)\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', class_='wikitable sortable')\n",
    "        \n",
    "        if table:\n",
    "            df = pd.read_html(str(table))[0]\n",
    "            results[f\"{yr}_{state}\"] = df\n",
    "\n",
    "del results['1988_Louisiana'] # Needs to be added manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c6e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Flatten the dfs\n",
    "for df in results.values():\n",
    "    df.columns = ['_'.join(col) for col in df.columns]\n",
    "\n",
    "## Filter out for only necessary columns\n",
    "# DFL was added since the wiki page for Minnesota lists Dem candidates as DFL\n",
    "pattern = re.compile('|'.join(['DFL', 'Democratic', 'Republican', 'Total']), flags=re.IGNORECASE)\n",
    "\n",
    "# Keep the first column and filter the rest\n",
    "for key, df in results.items():\n",
    "    first_col = df.iloc[:, 0]\n",
    "    filtered_df = df[df.columns[df.columns.str.contains(pattern, regex=True)]]\n",
    "    cols = filtered_df.columns\n",
    "    for col in cols:\n",
    "        if '%' in col:\n",
    "            filtered_df.drop(col, axis=1, inplace=True)\n",
    "    results[key] = pd.concat([first_col, filtered_df], axis=1)\n",
    "            \n",
    "## Rename columns\n",
    "for df in results.values():\n",
    "    cols = df.columns\n",
    "    df.rename(columns = {cols[0]: 'county', cols[3]:'total'}, inplace=True)\n",
    "    if ('Democratic' or 'DFL') in cols[1]:\n",
    "        df.rename(columns = {cols[1]: 'dem_votes', cols[2]: 'rep_votes'}, inplace=True)\n",
    "    else:\n",
    "        df.rename(columns = {cols[2]: 'dem_votes', cols[1]: 'rep_votes'}, inplace=True)\n",
    "        \n",
    "## LA needed to be added manually, bs4 won't scrape the info from wiki correctly\n",
    "results['1988_Louisiana'] = pd.read_csv('/Users/mattg/Personal Projects/2024_forecast/Data/election_results/1988_Louisiana_pres_county.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f64019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Example\n",
    "results['1996_Alabama'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save this info as multiple csv\n",
    "county_folder_path = '/Users/mattg/Personal Projects/2024_forecast/Data/election_results/county_results'\n",
    "\n",
    "'''\n",
    "for df in results.keys():\n",
    "    results[df].to_csv(f'{county_folder_path}/{df}.csv', index=False)  \n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
